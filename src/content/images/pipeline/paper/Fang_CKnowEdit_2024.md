---
title: "CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs"
authors: ["Tianhe Lu", "Jizhan Fang", "Yunzhi Yao", "Xin Xu", "Ningyu Zhang", "Huajun Chen"]
year: "2024"
conference: "ACL"
license: ""
tags: ["LLM", "Dataset", "Chinese"]
image: "Fang_CKnowEdit_2024.webp"
paper: "https://arxiv.org/pdf/2409.05806"
code: "https://github.com/zjunlp/EasyEdit"
project: ""
bibtex: "@inproceedings{fang2025cknowedit,
  title={Cknowedit: A new chinese knowledge editing dataset for linguistics, facts, and logic error correction in llms},
  author={Fang, Jizhan and Lu, Tianhe and Yao, Yunzhi and Jiang, Ziyan and Xu, Xin and Chen, Huajun and Zhang, Ningyu},
  booktitle={Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8789--8807},
  year={2025}
}}"
---

Chinese, as a linguistic system rich in depth and complexity, is characterized by distinctive elements such as ancient poetry, proverbs, idioms, and other cultural constructs. However, current Large Language Models (LLMs) face limitations in these specialized domains, highlighting the need for the development of comprehensive datasets that can assess, continuously update, and progressively improve these culturally-grounded linguistic competencies through targeted training optimizations. To address this gap, we introduce CKnowEdit, the first-ever Chinese knowledge editing dataset designed to correct linguistic, factual, and logical errors in LLMs. We collect seven types of knowledge from a wide range of sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, taking into account the unique polyphony, antithesis, and logical structures inherent in the Chinese language. By analyzing this dataset, we highlight the challenges current LLMs face in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge editing techniques reveals opportunities to advance the correction of Chinese knowledge.
